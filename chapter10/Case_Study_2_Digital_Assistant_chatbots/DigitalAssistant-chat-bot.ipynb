{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "# Digital Assistant: chat-bots\n",
    "\n",
    "In this case study we build a chatbot prototype using NLP and\n",
    "ML to understand the user’s intent and have response provided based on underlying logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Problem Definition](#1)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#2)\n",
    "    * [2.1. Load Libraries](#2.1) \n",
    "* [3. Training a default chatbot ](#3)  \n",
    "* [4. Data Preparation for customized chatbot](#4)\n",
    "* [5.Model Construction and Training](#5)        \n",
    "    * [5.1. Model Construction](#5.1)\n",
    "    * [5.2. Building Custom Logic Adapter](#5.2)\n",
    "    * [5.3. Training the model](#5.3)       \n",
    "* [6.Model Testing and Usage](#6)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this case study is to build a basic prototype of the conversational chatbot\n",
    "powered by NLP. The primary purpose of this chatbot would be to retrieve the finan‐\n",
    "cial ratio for the company user is looking for. Such chatbots designed to quickly\n",
    "retrieve the summary of a stock or instrument may help the user to make a trading\n",
    "decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# 2. Getting Started- Loading the data and python packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1. Loading the python packages\n",
    "For this case study we use python package - chatterbot. Chatterbot is a python library to create a simple chatbot with minimal programming required. \n",
    "Let us chek is the Chatterbot package is present, if not install it. This package is checked separately as it is not included in requirement.txt of this book repository as the package is not used across any other case study of thie book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import pip\n",
    "installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "if 'chatterbot' not in installedPackages :\n",
    "    !pip install ChatterBot==1.0.5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the chatterbot package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from chatterbot import ChatBot\n",
    "from chatterbot.logic import LogicAdapter\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move to the customised chatbot, let us develop a chatbot using the defualt features and logic adapters of chatterbot package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 Training a default chatbot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to build a chatbot for customised function avilable in chatterbot. Chatterbot and many other chatbot packages comes with a data utility module that can be used to train the chatbots.\n",
    "\n",
    "Following is a simple example to get started with ChatterBot in python with the following components. \n",
    "* **preprocessors** \n",
    "* **logic_adapters** \n",
    "* **corpus training** \n",
    "* **list training** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training ai.yml: [                    ] 1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tatsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tatsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "chatB = ChatBot(\"Trader\",\n",
    "                preprocessors=['chatterbot.preprocessors.clean_whitespace'],\n",
    "                logic_adapters=['chatterbot.logic.BestMatch',\n",
    "                                'chatterbot.logic.MathematicalEvaluation'])\n",
    "\n",
    "# Corpus Training\n",
    "trainerCorpus = ChatterBotCorpusTrainer(chatB)\n",
    "\n",
    "#Train based on English Corpus\n",
    "trainerCorpus.train(\n",
    "    \"chatterbot.corpus.english\"\n",
    ")\n",
    "# Train based on english greetings corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.greetings\")\n",
    "\n",
    "# Train based on the english conversations corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.conversations\")\n",
    "\n",
    "trainerConversation = ListTrainer(chatB)\n",
    "#Traing based on conversations\n",
    "\n",
    "#List training\n",
    "trainerConversation.train([\n",
    "    'Help!',\n",
    "    'Please go to google.com',\n",
    "    'What is Bitcoin?',\n",
    "    'It is a decentralized digital currency'\n",
    "])\n",
    "\n",
    "# You can train with a second list of data to add response variations\n",
    "trainerConversation.train([\n",
    "    'What is Bitcoin?',\n",
    "    'Bitcoin is a cryptocurrency.'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(quit=\"quit\"):\n",
    "    user_input = \"\"\n",
    "    while user_input != quit:\n",
    "        user_input = quit\n",
    "        try:\n",
    "            user_input = input(\">\")\n",
    "        except EOFError:\n",
    "            print(user_input)\n",
    "        if user_input:\n",
    "            while user_input[-1] in \"!.\":\n",
    "                user_input = user_input[:-1]\n",
    "            print(chatB.get_response(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Hi\n",
      "How are you doing?\n",
      ">I am doing well.\n",
      "That is good to hear\n",
      ">What is 78964 plus 5970\n",
      "78964 plus 5970 = 84934\n",
      ">what is a dollar\n",
      "dollar: unit of currency in the united states.\n",
      ">What is Bitcoin?\n",
      "It is a decentralized digital currency\n",
      ">Help!\n",
      "Please go to google.com\n",
      ">Tell me a joke\n",
      "Did you hear the one about the mountain goats in the andes? It was \"ba a a a a a d\".\n",
      ">What is Bitcoin?\n",
      "It is a decentralized digital currency\n",
      ">What is Bitcoin?\n",
      "It is a decentralized digital currency\n",
      ">What is Bitcoin?\n",
      "Bitcoin is a cryptocurrency.\n",
      ">quit\n",
      "no.\n"
     ]
    }
   ],
   "source": [
    "converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see a fairly good chatbot which gives us response according to the input that we have given. The first two responses are due to the training on english greetings and conversation corpus. Additionally the response to \"tell me a joke\" and \"what is a dollar\" are due to the training on the english corpus. The computation in the forth line is the result of the chatbot being trained on the Mathematical Evaluation logical adapter. The response to \"Help\" and \"What is a bitcoin\" are the result of the customised list trainers. \n",
    "\n",
    "Given, that we have already have a customised chatbot, we move on to create a chatbot which is designed to give us the financial ratios of a company based on a customised logical adapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 4. Data Preparation for customized chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of performing the data preparation is to use it for training through logic adapter.The details are under https://chatterbot.readthedocs.io/en/stable/logic/create-a-logic-adapter.html. Given the logic adapter need to be in a separate file from the chat bot, we perform the step of data preparation in the module **financial_ratio_adapter.py** where logic adapter is created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 5. Model construction and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1'></a>\n",
    "## 5.1 and 5.2 Model optimization function and building custom logic adapter\n",
    "Step 4.2 and 4.2 are shown in the module **financial_ratio_adapter.py**, given the logic adapter need to be in a separate file from the chat bot. In the next step we train the chatbot, which trains it on the customised logic adapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.3'></a>\n",
    "## 5.3. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we combine all the components (i.e. preprocessor, custom logical adapter, list and corpus trainer) with the custom logical adapter (financial_ratio_adapter.FinancialRatioAdapter) that we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 250.5925518564882}\n",
      "Losses {'ner': 86.34306746371182}\n",
      "Losses {'ner': 9.912364617525238}\n",
      "Losses {'ner': 0.007054564759577683}\n",
      "Losses {'ner': 0.002342427745124589}\n",
      "Losses {'ner': 0.17200641879483095}\n",
      "Losses {'ner': 0.00014026589302679004}\n",
      "Losses {'ner': 0.04666429370491898}\n",
      "Losses {'ner': 0.0005265609668528584}\n",
      "Losses {'ner': 0.00029906058166727796}\n",
      "Losses {'ner': 5.9895766629850823e-05}\n",
      "Losses {'ner': 0.0006064481033172622}\n",
      "Losses {'ner': 1.0745628683613567e-05}\n",
      "Losses {'ner': 9.724242475936387e-06}\n",
      "Losses {'ner': 1.7436667959465367e-06}\n",
      "Losses {'ner': 5.097320584206234e-07}\n",
      "Losses {'ner': 1.5063773009800355e-06}\n",
      "Losses {'ner': 3.463751450599309e-05}\n",
      "Losses {'ner': 8.846712629581901e-06}\n",
      "Losses {'ner': 5.9018098284142235e-05}\n",
      "Losses {'ner': 6.828183680571441e-07}\n",
      "Losses {'ner': 0.0001549424831125363}\n",
      "Losses {'ner': 0.00011724383958802145}\n",
      "Losses {'ner': 2.327508621099159e-06}\n",
      "Losses {'ner': 2.080900377673051e-05}\n",
      "Losses {'ner': 6.029163538041867e-07}\n",
      "Losses {'ner': 1.5160512220542697e-06}\n",
      "Losses {'ner': 3.181407171575549e-05}\n",
      "Losses {'ner': 9.974447850317994e-05}\n",
      "Losses {'ner': 0.0009394966254818016}\n",
      "Training ai.yml: [######              ] 31%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tatsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tatsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "#Here we add \n",
    "chatbot = ChatBot(\n",
    "    \"My ChatterBot\",\n",
    "    preprocessors=['chatterbot.preprocessors.clean_whitespace'],\n",
    "    logic_adapters=[\n",
    "        'financial_ratio_adapter.FinancialRatioAdapter',\n",
    "        'chatterbot.logic.MathematicalEvaluation',\n",
    "        'chatterbot.logic.BestMatch'\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Train based on English Corpus\n",
    "trainerCorpus.train(\n",
    "    \"chatterbot.corpus.english\"\n",
    ")\n",
    "# Train based on english greetings corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.greetings\")\n",
    "\n",
    "# Train based on the english conversations corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.conversations\")\n",
    "\n",
    "trainerConversation = ListTrainer(chatB)\n",
    "#Traing based on conversations\n",
    "\n",
    "trainerConversation.train([\n",
    "    'Help!',\n",
    "    'Please go to google.com',\n",
    "    'What is Bitcoin?',\n",
    "    'It is a decentralized digital currency'\n",
    "])\n",
    "\n",
    "# You can train with a second list of data to add response variations\n",
    "trainerConversation.train([\n",
    "    'What is Bitcoin?',\n",
    "    'Bitcoin is a cryptocurrency.'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the training was not only for the FinancialRatioAdapter, but also for the list and corpus trainer. Let us move to the model testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 6. Model Testing and Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(quit=\"quit\"):\n",
    "    user_input = \"\"\n",
    "    while user_input != quit:\n",
    "        user_input = quit\n",
    "        try:\n",
    "            user_input = input(\">\")\n",
    "        except EOFError:\n",
    "            print(user_input)\n",
    "        if user_input:\n",
    "            while user_input[-1] in \"!.\":\n",
    "                user_input = user_input[:-1]\n",
    "            print(chatbot.get_response(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">What is ROE for Citibank ?\n",
      "https://www.zacks.com/stock/chart/C/fundamental/return-on-equity-ttm\n",
      "\t\t\t\t\t  \n",
      ">Tell me PE for Delta?\n",
      "https://www.zacks.com/stock/chart/DAL/fundamental/pe-ratio-ttm\n",
      "\t\t\t\t\t  \n",
      ">What is Bitcoin?\n",
      "It is a decentralized digital currency\n",
      ">Help!\n",
      "Please go to google.com\n",
      ">What is 786940 plus 75869\n",
      "786940 plus 75869 = 862809\n",
      ">Do you like dogs?\n",
      "Sorry! Could not figure out what the user wants\n",
      ">Quit\n",
      "Sorry! Could not figure out what the user wants\n",
      ">quit\n",
      "Sorry! Could not figure out what the user wants\n"
     ]
    }
   ],
   "source": [
    "converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom logic adaptor for our Chatter bot, finds a RATIO or a COMPANY in the sentence using our NLP model. If the model finds exactly one COMPANY and exactly one RATIO, it con structs a url to guide the user. Additionally other logical adpater such as mathematical evaluation, and curpus and list trainer work as expected as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "In this case study, we have learned how to make a chatbot in python using the ChatterBot library. We learnt how to build a custom NLP based model focusing on NER(Named Entity Recognition) and use in a chatbot.\n",
    "\n",
    "\n",
    "In order to train a blank model, one must have a substantial training dataset. In this\n",
    "case study, we looked at patterns available to us and used them to generate training\n",
    "samples. \n",
    "\n",
    "This case study is a demo project, and significant enhancements can be made for each\n",
    "component to extend it for a wide variety of tasks. Additional preprocessing steps can\n",
    "be added to have cleaner data to work with. \n",
    "\n",
    "Overall, this case study provides an introduction to all the aspects of chatbot development. Although, it is a very simple bot, it’s a good starting point to use NLP to create\n",
    "chatbots.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
